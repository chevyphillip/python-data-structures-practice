{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functools Module Mastery - Functional Programming Tools\n",
    "## ðŸŸ¡ Intermediate Level\n",
    "\n",
    "**Goal**: Master Python's functools module for functional programming and optimization\n",
    "\n",
    "**Time**: ~50 minutes\n",
    "\n",
    "**Prerequisites**: Complete previous intermediate notebooks\n",
    "\n",
    "**Functions Covered**: `partial`, `reduce`, `lru_cache`, `singledispatch`, `wraps`, `cached_property`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functools and other required modules\n",
    "import functools\n",
    "from functools import partial, reduce, lru_cache, singledispatch, wraps, cached_property\n",
    "import time\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: partial - Partial Function Application\n",
    "\n",
    "**Concept**: `partial` creates new functions by fixing some arguments of existing functions\n",
    "\n",
    "**Use Cases**: Creating specialized functions, callback configuration, API simplification\n",
    "\n",
    "**Benefits**: Reduces code duplication, improves readability, enables functional composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Basic partial usage\n",
    "def multiply(x, y, z=1):\n",
    "    return x * y * z\n",
    "\n",
    "# Create specialized functions using partial\n",
    "double = partial(multiply, 2)  # Fix first argument to 2\n",
    "triple = partial(multiply, 3)  # Fix first argument to 3\n",
    "square = partial(multiply, y=2)  # Fix y argument to 2 (using keyword)\n",
    "\n",
    "print(f\"Original function: multiply(4, 5) = {multiply(4, 5)}\")\n",
    "print(f\"Double function: double(5) = {double(5)}\")\n",
    "print(f\"Triple function: triple(4) = {triple(4)}\")\n",
    "print(f\"Square function: square(6) = {square(6)}\")\n",
    "\n",
    "# Practical example: Logging with different levels\n",
    "def log_message(level, message, timestamp=None):\n",
    "    if timestamp is None:\n",
    "        timestamp = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return f\"[{timestamp}] {level}: {message}\"\n",
    "\n",
    "# Create specialized logging functions\n",
    "log_error = partial(log_message, 'ERROR')\n",
    "log_warning = partial(log_message, 'WARNING')\n",
    "log_info = partial(log_message, 'INFO')\n",
    "\n",
    "print(f\"\\nLogging examples:\")\n",
    "print(log_error(\"Database connection failed\"))\n",
    "print(log_warning(\"Memory usage is high\"))\n",
    "print(log_info(\"Application started successfully\"))\n",
    "\n",
    "# Using partial with built-in functions\n",
    "from operator import mul\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Create a function that multiplies by 10\n",
    "multiply_by_10 = partial(mul, 10)\n",
    "result = list(map(multiply_by_10, numbers))\n",
    "print(f\"\\nMultiply by 10: {numbers} -> {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Configuration System with partial\n",
    "\n",
    "**Scenario**: Build a flexible configuration system for different environments.\n",
    "\n",
    "**Tasks**:\n",
    "1. Create database connection functions for different environments\n",
    "2. Build API client functions with different base URLs\n",
    "3. Create validation functions with different rules\n",
    "4. Implement event handlers with partial configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Configuration System with partial\n",
    "\n",
    "# Base functions\n",
    "def connect_database(host, port, database, username, password, ssl=True):\n",
    "    return f\"Connected to {database} at {host}:{port} (SSL: {ssl})\"\n",
    "\n",
    "def make_api_request(base_url, endpoint, method='GET', headers=None, timeout=30):\n",
    "    headers = headers or {}\n",
    "    return f\"{method} {base_url}/{endpoint} (timeout: {timeout}s, headers: {len(headers)})\"\n",
    "\n",
    "def validate_data(data, min_length=1, max_length=100, required_fields=None):\n",
    "    required_fields = required_fields or []\n",
    "    return f\"Validating: length {min_length}-{max_length}, required: {required_fields}\"\n",
    "\n",
    "# TODO: Create environment-specific database connections\n",
    "connect_dev_db = partial(\n",
    "    connect_database,\n",
    "    host='dev-server',\n",
    "    port=5432,\n",
    "    database='dev_db',\n",
    "    ssl=False\n",
    ")\n",
    "\n",
    "connect_prod_db = partial(\n",
    "    connect_database,\n",
    "    host='prod-server',\n",
    "    port=5432,\n",
    "    database='prod_db',\n",
    "    ssl=True\n",
    ")\n",
    "\n",
    "# TODO: Create API clients for different services\n",
    "user_api = partial(make_api_request, 'https://api.users.com')\n",
    "payment_api = partial(make_api_request, 'https://api.payments.com', timeout=60)\n",
    "notification_api = partial(\n",
    "    make_api_request,\n",
    "    'https://api.notifications.com',\n",
    "    headers={'Authorization': 'Bearer token123'}\n",
    ")\n",
    "\n",
    "# TODO: Create validation functions for different data types\n",
    "validate_username = partial(\n",
    "    validate_data,\n",
    "    min_length=3,\n",
    "    max_length=20,\n",
    "    required_fields=['username']\n",
    ")\n",
    "\n",
    "validate_email = partial(\n",
    "    validate_data,\n",
    "    min_length=5,\n",
    "    max_length=100,\n",
    "    required_fields=['email', 'domain']\n",
    ")\n",
    "\n",
    "# Demo the configured functions\n",
    "print(\"Database Connections:\")\n",
    "print(f\"  Dev: {connect_dev_db('dev_user', 'dev_pass')}\")\n",
    "print(f\"  Prod: {connect_prod_db('prod_user', 'prod_pass')}\")\n",
    "\n",
    "print(\"\\nAPI Requests:\")\n",
    "print(f\"  Users: {user_api('profile/123')}\")\n",
    "print(f\"  Payments: {payment_api('transactions', method='POST')}\")\n",
    "print(f\"  Notifications: {notification_api('send')}\")\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "print(f\"  Username: {validate_username({'username': 'alice'})}\")\n",
    "print(f\"  Email: {validate_email({'email': 'test@example.com', 'domain': 'example.com'})}\")\n",
    "\n",
    "# Show partial function properties\n",
    "print(f\"\\nPartial function info:\")\n",
    "print(f\"  user_api.func: {user_api.func.__name__}\")\n",
    "print(f\"  user_api.args: {user_api.args}\")\n",
    "print(f\"  user_api.keywords: {user_api.keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: reduce - Cumulative Operations\n",
    "\n",
    "**Concept**: `reduce` applies a function cumulatively to items in a sequence\n",
    "\n",
    "**Use Cases**: Aggregations, mathematical operations, data folding\n",
    "\n",
    "**Pattern**: `reduce(function, iterable[, initializer])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Basic reduce operations\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Sum using reduce (equivalent to sum())\n",
    "total = reduce(lambda x, y: x + y, numbers)\n",
    "print(f\"Sum using reduce: {total}\")\n",
    "print(f\"Sum using built-in: {sum(numbers)}\")\n",
    "\n",
    "# Product using reduce\n",
    "product = reduce(lambda x, y: x * y, numbers)\n",
    "print(f\"Product: {product}\")\n",
    "\n",
    "# Maximum using reduce (equivalent to max())\n",
    "maximum = reduce(lambda x, y: x if x > y else y, numbers)\n",
    "print(f\"Maximum using reduce: {maximum}\")\n",
    "print(f\"Maximum using built-in: {max(numbers)}\")\n",
    "\n",
    "# Using operator functions with reduce\n",
    "import operator\n",
    "sum_op = reduce(operator.add, numbers)\n",
    "product_op = reduce(operator.mul, numbers)\n",
    "print(f\"\\nUsing operator functions:\")\n",
    "print(f\"  Sum: {sum_op}\")\n",
    "print(f\"  Product: {product_op}\")\n",
    "\n",
    "# Reduce with initializer\n",
    "sum_with_init = reduce(operator.add, numbers, 100)  # Start with 100\n",
    "print(f\"Sum with initializer 100: {sum_with_init}\")\n",
    "\n",
    "# Practical example: Flattening nested lists\n",
    "nested_lists = [[1, 2], [3, 4], [5, 6, 7]]\n",
    "flattened = reduce(operator.add, nested_lists)\n",
    "print(f\"\\nFlattening: {nested_lists} -> {flattened}\")\n",
    "\n",
    "# Complex example: Building a dictionary from pairs\n",
    "pairs = [('a', 1), ('b', 2), ('c', 3), ('a', 4)]  # Note: 'a' appears twice\n",
    "\n",
    "def merge_pairs(acc, pair):\n",
    "    key, value = pair\n",
    "    if key in acc:\n",
    "        acc[key] += value  # Add to existing value\n",
    "    else:\n",
    "        acc[key] = value\n",
    "    return acc\n",
    "\n",
    "result_dict = reduce(merge_pairs, pairs, {})\n",
    "print(f\"\\nMerging pairs: {pairs} -> {result_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Data Processing Pipeline with reduce\n",
    "\n",
    "**Scenario**: Build data processing pipelines using reduce for various aggregations.\n",
    "\n",
    "**Tasks**:\n",
    "1. Calculate statistics from transaction data\n",
    "2. Build nested data structures from flat data\n",
    "3. Implement custom aggregation functions\n",
    "4. Create data transformation pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Data Processing Pipeline with reduce\n",
    "\n",
    "# Sample transaction data\n",
    "transactions = [\n",
    "    {'id': 1, 'user': 'Alice', 'amount': 100, 'category': 'food'},\n",
    "    {'id': 2, 'user': 'Bob', 'amount': 50, 'category': 'transport'},\n",
    "    {'id': 3, 'user': 'Alice', 'amount': 75, 'category': 'food'},\n",
    "    {'id': 4, 'user': 'Charlie', 'amount': 200, 'category': 'entertainment'},\n",
    "    {'id': 5, 'user': 'Bob', 'amount': 30, 'category': 'food'},\n",
    "    {'id': 6, 'user': 'Alice', 'amount': 120, 'category': 'transport'}\n",
    "]\n",
    "\n",
    "# TODO: Calculate total spending per user\n",
    "def aggregate_by_user(acc, transaction):\n",
    "    user = transaction['user']\n",
    "    amount = transaction['amount']\n",
    "    acc[user] = acc.get(user, 0) + amount\n",
    "    return acc\n",
    "\n",
    "user_totals = reduce(aggregate_by_user, transactions, {})\n",
    "print(f\"Total spending by user: {user_totals}\")\n",
    "\n",
    "# TODO: Calculate spending by category\n",
    "def aggregate_by_category(acc, transaction):\n",
    "    category = transaction['category']\n",
    "    amount = transaction['amount']\n",
    "    acc[category] = acc.get(category, 0) + amount\n",
    "    return acc\n",
    "\n",
    "category_totals = reduce(aggregate_by_category, transactions, {})\n",
    "print(f\"Total spending by category: {category_totals}\")\n",
    "\n",
    "# TODO: Build nested structure: user -> category -> total\n",
    "def build_nested_structure(acc, transaction):\n",
    "    user = transaction['user']\n",
    "    category = transaction['category']\n",
    "    amount = transaction['amount']\n",
    "    \n",
    "    if user not in acc:\n",
    "        acc[user] = {}\n",
    "    \n",
    "    acc[user][category] = acc[user].get(category, 0) + amount\n",
    "    return acc\n",
    "\n",
    "nested_data = reduce(build_nested_structure, transactions, {})\n",
    "print(f\"\\nNested structure:\")\n",
    "for user, categories in nested_data.items():\n",
    "    print(f\"  {user}: {categories}\")\n",
    "\n",
    "# TODO: Calculate comprehensive statistics\n",
    "def calculate_stats(acc, transaction):\n",
    "    amount = transaction['amount']\n",
    "    \n",
    "    acc['count'] += 1\n",
    "    acc['total'] += amount\n",
    "    acc['min'] = min(acc['min'], amount)\n",
    "    acc['max'] = max(acc['max'], amount)\n",
    "    acc['amounts'].append(amount)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "initial_stats = {\n",
    "    'count': 0,\n",
    "    'total': 0,\n",
    "    'min': float('inf'),\n",
    "    'max': float('-inf'),\n",
    "    'amounts': []\n",
    "}\n",
    "\n",
    "stats = reduce(calculate_stats, transactions, initial_stats)\n",
    "stats['average'] = stats['total'] / stats['count']\n",
    "stats['median'] = sorted(stats['amounts'])[len(stats['amounts']) // 2]\n",
    "\n",
    "print(f\"\\nTransaction statistics:\")\n",
    "print(f\"  Count: {stats['count']}\")\n",
    "print(f\"  Total: ${stats['total']}\")\n",
    "print(f\"  Average: ${stats['average']:.2f}\")\n",
    "print(f\"  Median: ${stats['median']}\")\n",
    "print(f\"  Range: ${stats['min']} - ${stats['max']}\")\n",
    "\n",
    "# TODO: Create a data transformation pipeline\n",
    "def transform_and_filter(acc, transaction):\n",
    "    # Only include transactions > $50\n",
    "    if transaction['amount'] > 50:\n",
    "        # Transform the data\n",
    "        transformed = {\n",
    "            'user_category': f\"{transaction['user']}_{transaction['category']}\",\n",
    "            'amount_tier': 'high' if transaction['amount'] > 100 else 'medium'\n",
    "        }\n",
    "        acc.append(transformed)\n",
    "    return acc\n",
    "\n",
    "transformed_data = reduce(transform_and_filter, transactions, [])\n",
    "print(f\"\\nTransformed data (amount > $50): {transformed_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: lru_cache - Memoization for Performance\n",
    "\n",
    "**Concept**: `lru_cache` caches function results to avoid repeated calculations\n",
    "\n",
    "**Use Cases**: Expensive computations, recursive functions, API calls\n",
    "\n",
    "**Parameters**: `maxsize` (cache size), `typed` (type-sensitive caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Basic lru_cache usage\n",
    "import time\n",
    "\n",
    "# Expensive function without caching\n",
    "def fibonacci_slow(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci_slow(n-1) + fibonacci_slow(n-2)\n",
    "\n",
    "# Same function with caching\n",
    "@lru_cache(maxsize=128)\n",
    "def fibonacci_fast(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci_fast(n-1) + fibonacci_fast(n-2)\n",
    "\n",
    "# Compare performance\n",
    "n = 30\n",
    "\n",
    "start_time = time.time()\n",
    "result_slow = fibonacci_slow(n)\n",
    "slow_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "result_fast = fibonacci_fast(n)\n",
    "fast_time = time.time() - start_time\n",
    "\n",
    "print(f\"Fibonacci({n}):\")\n",
    "print(f\"  Without cache: {result_slow} (took {slow_time:.4f}s)\")\n",
    "print(f\"  With cache: {result_fast} (took {fast_time:.4f}s)\")\n",
    "print(f\"  Speedup: {slow_time/fast_time:.1f}x faster\")\n",
    "\n",
    "# Cache statistics\n",
    "print(f\"\\nCache info: {fibonacci_fast.cache_info()}\")\n",
    "\n",
    "# Clear cache\n",
    "fibonacci_fast.cache_clear()\n",
    "print(f\"After clearing: {fibonacci_fast.cache_info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Practical caching scenarios\n",
    "\n",
    "# 1. Expensive database-like operation\n",
    "@lru_cache(maxsize=100)\n",
    "def get_user_data(user_id):\n",
    "    # Simulate expensive database query\n",
    "    time.sleep(0.1)  # Simulate network delay\n",
    "    return {\n",
    "        'id': user_id,\n",
    "        'name': f'User{user_id}',\n",
    "        'email': f'user{user_id}@example.com'\n",
    "    }\n",
    "\n",
    "# 2. Complex calculation\n",
    "@lru_cache(maxsize=50)\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    # Simulate complex calculation\n",
    "    import math\n",
    "    time.sleep(0.05)  # Simulate computation time\n",
    "    return math.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "\n",
    "# 3. File processing with caching\n",
    "@lru_cache(maxsize=20)\n",
    "def process_file_content(filename, operation='count_lines'):\n",
    "    # Simulate file processing\n",
    "    time.sleep(0.2)  # Simulate I/O time\n",
    "    \n",
    "    if operation == 'count_lines':\n",
    "        return f\"File {filename} has 100 lines\"\n",
    "    elif operation == 'word_count':\n",
    "        return f\"File {filename} has 500 words\"\n",
    "    else:\n",
    "        return f\"Unknown operation for {filename}\"\n",
    "\n",
    "# Demo the cached functions\n",
    "print(\"Testing cached functions:\")\n",
    "\n",
    "# First calls (cache miss)\n",
    "start = time.time()\n",
    "user1 = get_user_data(1)\n",
    "user2 = get_user_data(2)\n",
    "dist1 = calculate_distance(0, 0, 3, 4)\n",
    "file1 = process_file_content('data.txt', 'count_lines')\n",
    "first_call_time = time.time() - start\n",
    "\n",
    "# Second calls (cache hit)\n",
    "start = time.time()\n",
    "user1_cached = get_user_data(1)  # Should be instant\n",
    "user2_cached = get_user_data(2)  # Should be instant\n",
    "dist1_cached = calculate_distance(0, 0, 3, 4)  # Should be instant\n",
    "file1_cached = process_file_content('data.txt', 'count_lines')  # Should be instant\n",
    "second_call_time = time.time() - start\n",
    "\n",
    "print(f\"First calls (cache miss): {first_call_time:.3f}s\")\n",
    "print(f\"Second calls (cache hit): {second_call_time:.3f}s\")\n",
    "print(f\"Speedup: {first_call_time/second_call_time:.1f}x\")\n",
    "\n",
    "# Show cache statistics\n",
    "print(f\"\\nCache statistics:\")\n",
    "print(f\"  get_user_data: {get_user_data.cache_info()}\")\n",
    "print(f\"  calculate_distance: {calculate_distance.cache_info()}\")\n",
    "print(f\"  process_file_content: {process_file_content.cache_info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: singledispatch - Function Overloading\n",
    "\n",
    "**Concept**: `singledispatch` creates generic functions that behave differently based on argument type\n",
    "\n",
    "**Use Cases**: Type-specific processing, API design, polymorphism\n",
    "\n",
    "**Benefits**: Clean code organization, extensible design, type safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Basic singledispatch usage\n",
    "from functools import singledispatch\n",
    "\n",
    "# Generic function (default implementation)\n",
    "@singledispatch\n",
    "def process_data(data):\n",
    "    return f\"Processing unknown type: {type(data).__name__}\"\n",
    "\n",
    "# Register implementations for specific types\n",
    "@process_data.register\n",
    "def _(data: str):\n",
    "    return f\"Processing string: '{data}' (length: {len(data)})\"\n",
    "\n",
    "@process_data.register\n",
    "def _(data: list):\n",
    "    return f\"Processing list: {len(data)} items, sum: {sum(data) if all(isinstance(x, (int, float)) for x in data) else 'N/A'}\"\n",
    "\n",
    "@process_data.register\n",
    "def _(data: dict):\n",
    "    return f\"Processing dict: {len(data)} keys: {list(data.keys())}\"\n",
    "\n",
    "@process_data.register\n",
    "def _(data: int):\n",
    "    return f\"Processing integer: {data} (even: {data % 2 == 0})\"\n",
    "\n",
    "# Test the generic function\n",
    "test_data = [\n",
    "    \"hello world\",\n",
    "    [1, 2, 3, 4, 5],\n",
    "    {'name': 'Alice', 'age': 30},\n",
    "    42,\n",
    "    3.14,  # No specific handler, will use default\n",
    "    (1, 2, 3)  # No specific handler, will use default\n",
    "]\n",
    "\n",
    "print(\"Single dispatch examples:\")\n",
    "for data in test_data:\n",
    "    result = process_data(data)\n",
    "    print(f\"  {result}\")\n",
    "\n",
    "# Show registered implementations\n",
    "print(f\"\\nRegistered types: {list(process_data.registry.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Practical singledispatch - Data serialization\n",
    "import json\n",
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "\n",
    "@singledispatch\n",
    "def serialize(obj):\n",
    "    \"\"\"Generic serialization function\"\"\"\n",
    "    return str(obj)  # Default: convert to string\n",
    "\n",
    "@serialize.register\n",
    "def _(obj: dict):\n",
    "    \"\"\"Serialize dictionary to JSON\"\"\"\n",
    "    return json.dumps(obj, indent=2)\n",
    "\n",
    "@serialize.register\n",
    "def _(obj: list):\n",
    "    \"\"\"Serialize list with custom formatting\"\"\"\n",
    "    return f\"[{', '.join(serialize(item) for item in obj)}]\"\n",
    "\n",
    "@serialize.register\n",
    "def _(obj: datetime):\n",
    "    \"\"\"Serialize datetime to ISO format\"\"\"\n",
    "    return obj.isoformat()\n",
    "\n",
    "@serialize.register\n",
    "def _(obj: Decimal):\n",
    "    \"\"\"Serialize Decimal to string with precision\"\"\"\n",
    "    return f\"${obj:.2f}\"\n",
    "\n",
    "@serialize.register\n",
    "def _(obj: bool):\n",
    "    \"\"\"Serialize boolean to lowercase string\"\"\"\n",
    "    return str(obj).lower()\n",
    "\n",
    "# Test serialization\n",
    "test_objects = [\n",
    "    {'name': 'Alice', 'active': True},\n",
    "    [1, 2, 3, 'hello'],\n",
    "    datetime.now(),\n",
    "    Decimal('123.456'),\n",
    "    True,\n",
    "    False,\n",
    "    \"regular string\"\n",
    "]\n",
    "\n",
    "print(\"Serialization examples:\")\n",
    "for obj in test_objects:\n",
    "    serialized = serialize(obj)\n",
    "    print(f\"  {type(obj).__name__}: {serialized}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: wraps - Decorator Preservation\n",
    "\n",
    "**Concept**: `wraps` preserves function metadata when creating decorators\n",
    "\n",
    "**Use Cases**: Building decorators, maintaining function introspection\n",
    "\n",
    "**Benefits**: Preserves `__name__`, `__doc__`, `__module__`, and other attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Decorator without wraps (problematic)\n",
    "def bad_timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"Function took {end - start:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Decorator with wraps (correct)\n",
    "def good_timer(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} took {end - start:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# Test functions\n",
    "@bad_timer\n",
    "def slow_function_bad():\n",
    "    \"\"\"This function simulates slow work\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return \"done\"\n",
    "\n",
    "@good_timer\n",
    "def slow_function_good():\n",
    "    \"\"\"This function simulates slow work\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    return \"done\"\n",
    "\n",
    "# Compare function metadata\n",
    "print(\"Function metadata comparison:\")\n",
    "print(f\"Bad decorator:\")\n",
    "print(f\"  Name: {slow_function_bad.__name__}\")\n",
    "print(f\"  Doc: {slow_function_bad.__doc__}\")\n",
    "\n",
    "print(f\"\\nGood decorator:\")\n",
    "print(f\"  Name: {slow_function_good.__name__}\")\n",
    "print(f\"  Doc: {slow_function_good.__doc__}\")\n",
    "\n",
    "# Test the functions\n",
    "print(\"\\nFunction execution:\")\n",
    "slow_function_bad()\n",
    "slow_function_good()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Building a comprehensive decorator with wraps\n",
    "def monitor(log_args=True, log_result=True, time_it=True):\n",
    "    \"\"\"Decorator that monitors function execution\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Log function call\n",
    "            if log_args:\n",
    "                print(f\"Calling {func.__name__} with args={args}, kwargs={kwargs}\")\n",
    "            \n",
    "            # Time execution\n",
    "            start = time.time() if time_it else None\n",
    "            \n",
    "            # Execute function\n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                \n",
    "                # Log result\n",
    "                if log_result:\n",
    "                    print(f\"{func.__name__} returned: {result}\")\n",
    "                \n",
    "                # Log timing\n",
    "                if time_it:\n",
    "                    duration = time.time() - start\n",
    "                    print(f\"{func.__name__} executed in {duration:.4f}s\")\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"{func.__name__} raised {type(e).__name__}: {e}\")\n",
    "                raise\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Test the comprehensive decorator\n",
    "@monitor(log_args=True, log_result=True, time_it=True)\n",
    "def calculate_factorial(n):\n",
    "    \"\"\"Calculate factorial of n\"\"\"\n",
    "    if n < 0:\n",
    "        raise ValueError(\"Factorial not defined for negative numbers\")\n",
    "    if n <= 1:\n",
    "        return 1\n",
    "    return n * calculate_factorial(n - 1)\n",
    "\n",
    "@monitor(log_args=False, log_result=True, time_it=False)\n",
    "def greet(name, greeting=\"Hello\"):\n",
    "    \"\"\"Greet someone with a custom message\"\"\"\n",
    "    return f\"{greeting}, {name}!\"\n",
    "\n",
    "# Test the decorated functions\n",
    "print(\"Testing monitored functions:\")\n",
    "print(f\"\\nFactorial function metadata:\")\n",
    "print(f\"  Name: {calculate_factorial.__name__}\")\n",
    "print(f\"  Doc: {calculate_factorial.__doc__}\")\n",
    "\n",
    "print(f\"\\nExecuting functions:\")\n",
    "result1 = calculate_factorial(5)\n",
    "print()\n",
    "result2 = greet(\"Alice\", greeting=\"Hi\")\n",
    "print()\n",
    "\n",
    "# Test error handling\n",
    "try:\n",
    "    calculate_factorial(-1)\n",
    "except ValueError:\n",
    "    print(\"Error was properly handled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Exercise: Advanced Calculator System\n",
    "\n",
    "**Scenario**: Build a sophisticated calculator system using all functools features.\n",
    "\n",
    "**Requirements**:\n",
    "- Use `partial` for operation configuration\n",
    "- Use `reduce` for complex calculations\n",
    "- Use `lru_cache` for expensive operations\n",
    "- Use `singledispatch` for type-specific handling\n",
    "- Use `wraps` for proper decorators\n",
    "- Implement history, validation, and performance monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Exercise: Advanced Calculator System\n",
    "\n",
    "class AdvancedCalculator:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "        self.operation_count = 0\n",
    "    \n",
    "    # Decorator for logging operations\n",
    "    def log_operation(self, func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            self.operation_count += 1\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                duration = time.time() - start_time\n",
    "                \n",
    "                # Log to history\n",
    "                self.history.append({\n",
    "                    'operation': func.__name__,\n",
    "                    'args': args,\n",
    "                    'result': result,\n",
    "                    'duration': duration,\n",
    "                    'count': self.operation_count\n",
    "                })\n",
    "                \n",
    "                print(f\"Operation {self.operation_count}: {func.__name__}{args} = {result} ({duration:.4f}s)\")\n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in {func.__name__}: {e}\")\n",
    "                raise\n",
    "        \n",
    "        return wrapper\n",
    "    \n",
    "    # Cached expensive operations\n",
    "    @lru_cache(maxsize=100)\n",
    "    def fibonacci(self, n):\n",
    "        \"\"\"Calculate Fibonacci number with caching\"\"\"\n",
    "        if n < 2:\n",
    "            return n\n",
    "        return self.fibonacci(n-1) + self.fibonacci(n-2)\n",
    "    \n",
    "    @lru_cache(maxsize=50)\n",
    "    def factorial(self, n):\n",
    "        \"\"\"Calculate factorial with caching\"\"\"\n",
    "        if n <= 1:\n",
    "            return 1\n",
    "        return n * self.factorial(n-1)\n",
    "    \n",
    "    @lru_cache(maxsize=50)\n",
    "    def prime_factors(self, n):\n",
    "        \"\"\"Find prime factors with caching\"\"\"\n",
    "        factors = []\n",
    "        d = 2\n",
    "        while d * d <= n:\n",
    "            while n % d == 0:\n",
    "                factors.append(d)\n",
    "                n //= d\n",
    "            d += 1\n",
    "        if n > 1:\n",
    "            factors.append(n)\n",
    "        return tuple(factors)  # Return tuple for hashability\n",
    "\n",
    "# Create calculator instance\n",
    "calc = AdvancedCalculator()\n",
    "\n",
    "# Apply logging decorator to methods\n",
    "calc.fibonacci = calc.log_operation(calc.fibonacci)\n",
    "calc.factorial = calc.log_operation(calc.factorial)\n",
    "calc.prime_factors = calc.log_operation(calc.prime_factors)\n",
    "\n",
    "# Test the calculator\n",
    "print(\"Advanced Calculator Demo:\")\n",
    "print()\n",
    "\n",
    "# Test cached operations\n",
    "fib_10 = calc.fibonacci(10)\n",
    "fib_10_again = calc.fibonacci(10)  # Should be cached\n",
    "\n",
    "fact_5 = calc.factorial(5)\n",
    "fact_6 = calc.factorial(6)  # Should reuse cached factorial(5)\n",
    "\n",
    "factors_60 = calc.prime_factors(60)\n",
    "factors_60_again = calc.prime_factors(60)  # Should be cached\n",
    "\n",
    "print(f\"\\nCache statistics:\")\n",
    "print(f\"  Fibonacci: {calc.fibonacci.cache_info()}\")\n",
    "print(f\"  Factorial: {calc.factorial.cache_info()}\")\n",
    "print(f\"  Prime factors: {calc.prime_factors.cache_info()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the calculator with singledispatch and partial\n",
    "\n",
    "# Generic calculation function using singledispatch\n",
    "@singledispatch\n",
    "def calculate(data):\n",
    "    \"\"\"Generic calculation function\"\"\"\n",
    "    return f\"Cannot calculate with {type(data).__name__}\"\n",
    "\n",
    "@calculate.register\n",
    "def _(data: list):\n",
    "    \"\"\"Calculate statistics for list of numbers\"\"\"\n",
    "    if not data or not all(isinstance(x, (int, float)) for x in data):\n",
    "        return \"Invalid numeric data\"\n",
    "    \n",
    "    total = reduce(operator.add, data)\n",
    "    product = reduce(operator.mul, data)\n",
    "    maximum = reduce(lambda x, y: x if x > y else y, data)\n",
    "    minimum = reduce(lambda x, y: x if x < y else y, data)\n",
    "    \n",
    "    return {\n",
    "        'sum': total,\n",
    "        'product': product,\n",
    "        'average': total / len(data),\n",
    "        'max': maximum,\n",
    "        'min': minimum,\n",
    "        'count': len(data)\n",
    "    }\n",
    "\n",
    "@calculate.register\n",
    "def _(data: dict):\n",
    "    \"\"\"Calculate from dictionary of operations\"\"\"\n",
    "    results = {}\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            results[key] = calculate(value)\n",
    "        else:\n",
    "            results[key] = value\n",
    "    return results\n",
    "\n",
    "@calculate.register\n",
    "def _(data: str):\n",
    "    \"\"\"Parse and calculate simple expressions\"\"\"\n",
    "    try:\n",
    "        # Simple evaluation (in real app, use proper parser)\n",
    "        if all(c in '0123456789+-*/.() ' for c in data):\n",
    "            return eval(data)  # WARNING: Only for demo, never use eval in production!\n",
    "        else:\n",
    "            return \"Invalid expression\"\n",
    "    except:\n",
    "        return \"Calculation error\"\n",
    "\n",
    "# Create specialized calculation functions using partial\n",
    "def apply_operation(operation, *numbers):\n",
    "    \"\"\"Apply operation to numbers\"\"\"\n",
    "    return reduce(operation, numbers)\n",
    "\n",
    "# Create specialized functions\n",
    "sum_numbers = partial(apply_operation, operator.add)\n",
    "multiply_numbers = partial(apply_operation, operator.mul)\n",
    "find_max = partial(apply_operation, lambda x, y: x if x > y else y)\n",
    "find_min = partial(apply_operation, lambda x, y: x if x < y else y)\n",
    "\n",
    "# Test the enhanced calculator\n",
    "print(\"\\nEnhanced Calculator Features:\")\n",
    "\n",
    "# Test singledispatch\n",
    "test_data = [\n",
    "    [1, 2, 3, 4, 5],\n",
    "    {'dataset1': [10, 20, 30], 'dataset2': [5, 15, 25]},\n",
    "    \"2 + 3 * 4\",\n",
    "    42  # Will use default implementation\n",
    "]\n",
    "\n",
    "for i, data in enumerate(test_data, 1):\n",
    "    result = calculate(data)\n",
    "    print(f\"\\nTest {i} ({type(data).__name__}): {data}\")\n",
    "    print(f\"Result: {result}\")\n",
    "\n",
    "# Test partial functions\n",
    "numbers = [10, 5, 8, 3, 12]\n",
    "print(f\"\\nPartial function tests with {numbers}:\")\n",
    "print(f\"  Sum: {sum_numbers(*numbers)}\")\n",
    "print(f\"  Product: {multiply_numbers(*numbers)}\")\n",
    "print(f\"  Maximum: {find_max(*numbers)}\")\n",
    "print(f\"  Minimum: {find_min(*numbers)}\")\n",
    "\n",
    "# Show operation history\n",
    "print(f\"\\nOperation History ({len(calc.history)} operations):\")\n",
    "for op in calc.history[-3:]:  # Show last 3 operations\n",
    "    print(f\"  {op['count']}: {op['operation']}{op['args']} = {op['result']} ({op['duration']:.4f}s)\")\n",
    "\n",
    "print(f\"\\nTotal operations performed: {calc.operation_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "**ðŸŽ‰ Congratulations!** You've mastered Python's functools module!\n",
    "\n",
    "### Functions Covered:\n",
    "\n",
    "**ðŸ”§ partial:**\n",
    "- Creating specialized functions by fixing arguments\n",
    "- Configuration and callback simplification\n",
    "- Functional composition patterns\n",
    "\n",
    "**ðŸ“Š reduce:**\n",
    "- Cumulative operations on sequences\n",
    "- Data aggregation and folding\n",
    "- Building complex data structures\n",
    "\n",
    "**âš¡ lru_cache:**\n",
    "- Memoization for performance optimization\n",
    "- Caching expensive computations\n",
    "- Cache management and statistics\n",
    "\n",
    "**ðŸŽ¯ singledispatch:**\n",
    "- Type-based function overloading\n",
    "- Clean polymorphic code\n",
    "- Extensible generic functions\n",
    "\n",
    "**ðŸ·ï¸ wraps:**\n",
    "- Preserving function metadata in decorators\n",
    "- Proper decorator implementation\n",
    "- Maintaining introspection capabilities\n",
    "\n",
    "### Key Benefits:\n",
    "- âœ… **Performance**: Caching and optimization tools\n",
    "- âœ… **Code Quality**: Cleaner, more maintainable code\n",
    "- âœ… **Flexibility**: Functional programming patterns\n",
    "- âœ… **Extensibility**: Generic and configurable functions\n",
    "\n",
    "### Best Practices:\n",
    "- Use `lru_cache` for expensive, pure functions\n",
    "- Always use `wraps` when creating decorators\n",
    "- Use `partial` to create specialized, reusable functions\n",
    "- Use `singledispatch` for clean type-based polymorphism\n",
    "- Use `reduce` for cumulative operations (prefer built-ins when available)\n",
    "\n",
    "### Next Steps:\n",
    "Ready for advanced Python topics? Try:\n",
    "- **Asyncio and concurrent programming**\n",
    "- **Context managers and descriptors**\n",
    "- **Metaclasses and advanced OOP**\n",
    "- **Performance profiling and optimization**\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸš€ Pro Tip**: Functools is essential for writing Pythonic, efficient code. These tools are commonly used in frameworks, libraries, and production systems. Master them to write more elegant and performant Python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
